{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Xavier and He Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<_ReuseMode.AUTO_REUSE: 1>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "import os\n",
    "\n",
    "tf.AUTO_REUSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#he_init= tf.variance_scaling_initializer()\n",
    "#hidden1= tf.layers.dense(X, n_hidden, activation= tf.nn.relu, kernel_initializer=he_init, name=\"hidden1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Leaky ReLU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def leaky_relu(z, name=None):\n",
    "    return tf.maximum(0.01 * z, z, name=name)\n",
    "\n",
    "he_init= tf.variance_scaling_initializer()\n",
    "#hidden1=tf.layers.dense(X, n_hidden, activation= leaky_relu, kernel_initializer=he_init, name=\"hidden1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "\n",
    "n_inputs= 28*28\n",
    "n_hidden1=300\n",
    "n_hidden2=100\n",
    "n_outputs= 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X= tf.placeholder(tf.float32, shape=(None, n_inputs), name=\"X\")\n",
    "y= tf.placeholder(tf.int32, shape=(None), name=\"y\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.name_scope(\"dnn\"):\n",
    "    hidden1= tf.layers.dense(X, n_hidden1, activation=leaky_relu, kernel_initializer=he_init, name=\"hidden1\")\n",
    "    hidden2= tf.layers.dense(hidden1, n_hidden2, activation=leaky_relu, kernel_initializer=he_init, name=\"hidden2\")\n",
    "    logits= tf.layers.dense(hidden2, n_outputs, name=\"output\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.name_scope(\"loss\"):\n",
    "    xentropy= tf.nn.sparse_softmax_cross_entropy_with_logits(labels=y, logits=logits)\n",
    "    loss= tf.reduce_mean(xentropy, name=\"cross_entropy\")\n",
    "    loss_summary= tf.summary.scalar('log_loss', loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.name_scope(\"eval\"):\n",
    "    correct= tf.nn.in_top_k(logits, y, 1)\n",
    "    accuracy= tf.reduce_mean(tf.cast(correct, tf.float32))\n",
    "    accuracy_summary= tf.summary.scalar('log_eval', accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr=0.01\n",
    "\n",
    "with tf.name_scope(\"train\"):\n",
    "    optimizer= tf.train.GradientDescentOptimizer(lr)\n",
    "    training_op= optimizer.minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "init= tf.global_variables_initializer()\n",
    "saver= tf.train.Saver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_dir(prefix=\"\"):\n",
    "    now= datetime.utcnow().strftime(\"%Y%M%D%H%M%S\")\n",
    "    root_logdir= \"C:/Users/soumyama/Documents/Python Scripts/Scikit Learn/tf_logs\"\n",
    "    if prefix:\n",
    "        prefix +=\"-\"\n",
    "    name= prefix + \"run-\" + now\n",
    "    return \"{}/{}/\".format(root_logdir, name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "logdir= log_dir(\"MNIST_dnn\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_writer= tf.summary.FileWriter(logdir, tf.get_default_graph())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train, y_train), (X_test, y_test)= tf.keras.datasets.mnist.load_data()\n",
    "X_train= X_train.reshape(-1, 784).astype(np.float32)/255.\n",
    "X_test= X_test.reshape(-1, 784).astype(np.float32)/255.\n",
    "y_train= y_train.astype(np.int32)\n",
    "y_test= y_test.astype(np.int32)\n",
    "\n",
    "X_valid, y_valid= X_train[:5000], y_train[:5000]\n",
    "X_train, y_train= X_train[5000:], y_train[5000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shuffle_batch(X, y, batch_size):\n",
    "    rnd_idx= np.random.permutation(len(X))\n",
    "    n_batches= len(X) //batch_size\n",
    "    for batch_idx in np.array_split(rnd_idx, n_batches):\n",
    "        X_batch, y_batch= X[batch_idx], y[batch_idx]\n",
    "        yield X_batch, y_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_path= \"C:/Users/soumyama/Documents/Python Scripts/Scikit Learn/checkpoint/mnist_model.ckpt\"\n",
    "checkpoint_epoch_path= checkpoint_path + \".epoch\"\n",
    "final_model_path= \"./deep_mnist_model/\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs=500\n",
    "batch_size=128\n",
    "\n",
    "best_loss= np.infty\n",
    "epochs_without_progress=0\n",
    "max_epochs_without_progress=50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  0 \tValidation Loss: 0.680 \tValidation Accuracy: 85.160%\n",
      "Epoch:  1 \tValidation Loss: 0.428 \tValidation Accuracy: 88.960%\n",
      "Epoch:  2 \tValidation Loss: 0.356 \tValidation Accuracy: 90.260%\n",
      "Epoch:  3 \tValidation Loss: 0.322 \tValidation Accuracy: 91.140%\n",
      "Epoch:  4 \tValidation Loss: 0.297 \tValidation Accuracy: 91.720%\n",
      "Epoch:  5 \tValidation Loss: 0.280 \tValidation Accuracy: 92.360%\n",
      "Epoch:  6 \tValidation Loss: 0.266 \tValidation Accuracy: 92.820%\n",
      "Epoch:  7 \tValidation Loss: 0.253 \tValidation Accuracy: 93.080%\n",
      "Epoch:  8 \tValidation Loss: 0.244 \tValidation Accuracy: 93.400%\n",
      "Epoch:  9 \tValidation Loss: 0.235 \tValidation Accuracy: 93.440%\n",
      "Epoch:  10 \tValidation Loss: 0.225 \tValidation Accuracy: 93.840%\n",
      "Epoch:  11 \tValidation Loss: 0.217 \tValidation Accuracy: 94.040%\n",
      "Epoch:  12 \tValidation Loss: 0.209 \tValidation Accuracy: 94.280%\n",
      "Epoch:  13 \tValidation Loss: 0.202 \tValidation Accuracy: 94.440%\n",
      "Epoch:  14 \tValidation Loss: 0.196 \tValidation Accuracy: 94.680%\n",
      "Epoch:  15 \tValidation Loss: 0.190 \tValidation Accuracy: 94.680%\n",
      "Epoch:  16 \tValidation Loss: 0.184 \tValidation Accuracy: 94.860%\n",
      "Epoch:  17 \tValidation Loss: 0.179 \tValidation Accuracy: 94.980%\n",
      "Epoch:  18 \tValidation Loss: 0.174 \tValidation Accuracy: 95.120%\n",
      "Epoch:  19 \tValidation Loss: 0.169 \tValidation Accuracy: 95.260%\n",
      "Epoch:  20 \tValidation Loss: 0.165 \tValidation Accuracy: 95.400%\n",
      "Epoch:  21 \tValidation Loss: 0.161 \tValidation Accuracy: 95.580%\n",
      "Epoch:  22 \tValidation Loss: 0.157 \tValidation Accuracy: 95.740%\n",
      "Epoch:  23 \tValidation Loss: 0.155 \tValidation Accuracy: 95.780%\n",
      "Epoch:  24 \tValidation Loss: 0.150 \tValidation Accuracy: 95.680%\n",
      "Epoch:  25 \tValidation Loss: 0.147 \tValidation Accuracy: 96.000%\n",
      "Epoch:  26 \tValidation Loss: 0.144 \tValidation Accuracy: 96.060%\n",
      "Epoch:  27 \tValidation Loss: 0.141 \tValidation Accuracy: 96.020%\n",
      "Epoch:  28 \tValidation Loss: 0.138 \tValidation Accuracy: 96.260%\n",
      "Epoch:  29 \tValidation Loss: 0.137 \tValidation Accuracy: 96.280%\n",
      "Epoch:  30 \tValidation Loss: 0.134 \tValidation Accuracy: 96.400%\n",
      "Epoch:  31 \tValidation Loss: 0.131 \tValidation Accuracy: 96.480%\n",
      "Epoch:  32 \tValidation Loss: 0.129 \tValidation Accuracy: 96.560%\n",
      "Epoch:  33 \tValidation Loss: 0.127 \tValidation Accuracy: 96.600%\n",
      "Epoch:  34 \tValidation Loss: 0.125 \tValidation Accuracy: 96.680%\n",
      "Epoch:  35 \tValidation Loss: 0.124 \tValidation Accuracy: 96.840%\n",
      "Epoch:  36 \tValidation Loss: 0.121 \tValidation Accuracy: 96.800%\n",
      "Epoch:  37 \tValidation Loss: 0.119 \tValidation Accuracy: 96.840%\n",
      "Epoch:  38 \tValidation Loss: 0.117 \tValidation Accuracy: 96.940%\n",
      "Epoch:  39 \tValidation Loss: 0.116 \tValidation Accuracy: 97.020%\n",
      "Epoch:  40 \tValidation Loss: 0.114 \tValidation Accuracy: 97.100%\n",
      "Epoch:  41 \tValidation Loss: 0.113 \tValidation Accuracy: 97.000%\n",
      "Epoch:  42 \tValidation Loss: 0.112 \tValidation Accuracy: 97.040%\n",
      "Epoch:  43 \tValidation Loss: 0.110 \tValidation Accuracy: 97.120%\n",
      "Epoch:  44 \tValidation Loss: 0.109 \tValidation Accuracy: 97.100%\n",
      "Epoch:  45 \tValidation Loss: 0.107 \tValidation Accuracy: 97.200%\n",
      "Epoch:  46 \tValidation Loss: 0.106 \tValidation Accuracy: 97.300%\n",
      "Epoch:  47 \tValidation Loss: 0.105 \tValidation Accuracy: 97.280%\n",
      "Epoch:  48 \tValidation Loss: 0.104 \tValidation Accuracy: 97.220%\n",
      "Epoch:  49 \tValidation Loss: 0.103 \tValidation Accuracy: 97.420%\n",
      "Epoch:  50 \tValidation Loss: 0.101 \tValidation Accuracy: 97.420%\n",
      "Epoch:  51 \tValidation Loss: 0.101 \tValidation Accuracy: 97.360%\n",
      "Epoch:  52 \tValidation Loss: 0.099 \tValidation Accuracy: 97.440%\n",
      "Epoch:  53 \tValidation Loss: 0.098 \tValidation Accuracy: 97.340%\n",
      "Epoch:  54 \tValidation Loss: 0.096 \tValidation Accuracy: 97.540%\n",
      "Epoch:  55 \tValidation Loss: 0.097 \tValidation Accuracy: 97.380%\n",
      "Epoch:  56 \tValidation Loss: 0.095 \tValidation Accuracy: 97.600%\n",
      "Epoch:  57 \tValidation Loss: 0.094 \tValidation Accuracy: 97.540%\n",
      "Epoch:  58 \tValidation Loss: 0.093 \tValidation Accuracy: 97.600%\n",
      "Epoch:  59 \tValidation Loss: 0.094 \tValidation Accuracy: 97.360%\n",
      "Epoch:  60 \tValidation Loss: 0.092 \tValidation Accuracy: 97.540%\n",
      "Epoch:  61 \tValidation Loss: 0.092 \tValidation Accuracy: 97.580%\n",
      "Epoch:  62 \tValidation Loss: 0.091 \tValidation Accuracy: 97.600%\n",
      "Epoch:  63 \tValidation Loss: 0.090 \tValidation Accuracy: 97.560%\n",
      "Epoch:  64 \tValidation Loss: 0.090 \tValidation Accuracy: 97.540%\n",
      "Epoch:  65 \tValidation Loss: 0.089 \tValidation Accuracy: 97.560%\n",
      "Epoch:  66 \tValidation Loss: 0.090 \tValidation Accuracy: 97.440%\n",
      "Epoch:  67 \tValidation Loss: 0.087 \tValidation Accuracy: 97.640%\n",
      "Epoch:  68 \tValidation Loss: 0.087 \tValidation Accuracy: 97.620%\n",
      "Epoch:  69 \tValidation Loss: 0.085 \tValidation Accuracy: 97.640%\n",
      "Epoch:  70 \tValidation Loss: 0.085 \tValidation Accuracy: 97.580%\n",
      "Epoch:  71 \tValidation Loss: 0.085 \tValidation Accuracy: 97.620%\n",
      "Epoch:  72 \tValidation Loss: 0.084 \tValidation Accuracy: 97.660%\n",
      "Epoch:  73 \tValidation Loss: 0.084 \tValidation Accuracy: 97.660%\n",
      "Epoch:  74 \tValidation Loss: 0.084 \tValidation Accuracy: 97.580%\n",
      "Epoch:  75 \tValidation Loss: 0.082 \tValidation Accuracy: 97.820%\n",
      "Epoch:  76 \tValidation Loss: 0.082 \tValidation Accuracy: 97.780%\n",
      "Epoch:  77 \tValidation Loss: 0.083 \tValidation Accuracy: 97.740%\n",
      "Epoch:  78 \tValidation Loss: 0.081 \tValidation Accuracy: 97.720%\n",
      "Epoch:  79 \tValidation Loss: 0.081 \tValidation Accuracy: 97.740%\n",
      "Epoch:  80 \tValidation Loss: 0.081 \tValidation Accuracy: 97.720%\n",
      "Epoch:  81 \tValidation Loss: 0.082 \tValidation Accuracy: 97.620%\n",
      "Epoch:  82 \tValidation Loss: 0.080 \tValidation Accuracy: 97.660%\n",
      "Epoch:  83 \tValidation Loss: 0.079 \tValidation Accuracy: 97.720%\n",
      "Epoch:  84 \tValidation Loss: 0.080 \tValidation Accuracy: 97.600%\n",
      "Epoch:  85 \tValidation Loss: 0.079 \tValidation Accuracy: 97.660%\n",
      "Epoch:  86 \tValidation Loss: 0.078 \tValidation Accuracy: 97.820%\n",
      "Epoch:  87 \tValidation Loss: 0.079 \tValidation Accuracy: 97.700%\n",
      "Early Stopping\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    if os.path.isfile(checkpoint_epoch_path):\n",
    "        with open(checkpoint_epoch_path, \"rb\") as f:\n",
    "            start_epoch= int(f.read())\n",
    "        print(\"Training was interrupted. Resuming from Epoch: \", start_epoch)\n",
    "        saver.restore(sess, checkpoint_path)\n",
    "    else:\n",
    "        start_epoch=0\n",
    "        sess.run(init)\n",
    "        \n",
    "    for epoch in range(start_epoch, n_epochs):\n",
    "        for X_batch, y_batch in shuffle_batch(X_train, y_train, batch_size):\n",
    "            sess.run(training_op, feed_dict={X: X_batch, y: y_batch})\n",
    "        accuracy_val, loss_val, accuracy_summary_str, loss_summary_str= sess.run([accuracy, loss, accuracy_summary,\n",
    "                                                                                  loss_summary], feed_dict={X: X_valid,\n",
    "                                                                                                          y: y_valid})\n",
    "        file_writer.add_summary(accuracy_summary_str, epoch)\n",
    "        file_writer.add_summary(loss_summary_str, epoch)\n",
    "        if epoch % 1 == 0:\n",
    "            print(\"Epoch: \", epoch, \"\\tValidation Loss: {:.3f}\".format(loss_val), \n",
    "                  \"\\tValidation Accuracy: {:.3f}%\".format(accuracy_val*100))\n",
    "            saver.save(sess, checkpoint_path)\n",
    "            with open(checkpoint_epoch_path, \"wb\") as f:\n",
    "                f.write(b\"%d\" % (epoch+1))\n",
    "            if loss_val < best_loss:\n",
    "                saver.save(sess, final_model_path)\n",
    "                best_loss= loss_val\n",
    "            else:\n",
    "                epochs_without_progress+=5\n",
    "                if epochs_without_progress> max_epochs_without_progress:\n",
    "                    print(\"Early Stopping\")\n",
    "                    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![png (2)](https://user-images.githubusercontent.com/13174586/54606356-a0bcd300-4a71-11e9-8869-5e57b73bff86.png)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
